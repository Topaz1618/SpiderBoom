爬虫被封原因：代码向服务器发送的请求和浏览器向服务器发送的请求不一样
打开浏览器 F12 可以看到浏览器访问服务器资源的流程和数据流向，数据流向包括：
1.浏览器向服务器发送的请求头
2.浏览器向服务器发送的请求体
3.（可能）服务器向浏览器发送的重定向地址及浏览器重新向新的地址发送请求
4.服务器返回的响应头
5.服务器返回的响应体

Http 请求报文 ： https://segmentfault.com/a/1190000006689767

如果爬虫被封，很可能是请求报文的问题，检查修复
一 、首先了解哈 requests 方法，get post session功能 和区别

session看这里：http://docs.python-requests.org/zh_CN/latest/user/advanced.html

二 、然后了解常见反爬虫思路与解决办法
	selenium打开网页输入用户名密码之后，这里主要分三种情况，如果没有验证码则直接登陆，如果遇到登陆限制则休眠起来，如果遇到验证码则把图片发送至打码平台然后等待获取到验证码结果再登陆，登陆成功之后会有一个访问个人测试的小主页，之后就是把cookie录入redis的数据库。

	另外一个定期检查cookie的进程是利用requests库访问个人主页，根据返回的结果判断cookie是否有效，无效则删除，检验的代码比较简单，如图

### 对付基于 cookie 的反爬
	163邮箱：
	mabljx2t@163.com----duofa855
	ppdiiybi43@163.com----qiuzen28
	xtlycw271yl@163.com----zen8944
	afiah894sk@163.com----qingmen1
	subcmc7360gq@163.com----cu323057
	u2228snq@163.com----reng5148
	hgwk1172py@163.com----botui750
	hjoce06vez@163.com----shu459
	ochou388@163.com----ji4532
	urdow7761p@163.com----chuang7
	csoxdx3y@163.com----han8622


	已注册账号：
		邮箱：sdefu477@163.com----wujie3  		微博账号：sdefu477@163.com----spiders
		邮箱：uhrzui8150670@163.com----mie429 	微博账号：uhrzui8150670@163.com----spiders
		邮箱：gjap62jk@163.com----lindie18 		微博账号：gjap62jk@163.com----spiders



    原理+判断：https://zhuanlan.zhihu.com/p/28097930
    解决：维护一个Cookie池，Cookie池需要具备些什么最基本的功能呢？
    参考1：https://cuiqingcai.com/4048.html
        获取Cookie
        更新Cookie
        删除Cookie
        判断Cookie是否可用进行相对应的操作（比如重试）

    参考2：https://juejin.im/post/5acc5b2ef265da239d49a155
        Cookies池需要有自动生成Cookies、定时检测Cookies、提供随机Cookies等几大核心功能。
    Cookies的架构和代理池类似，同样是4个核心模块，如下图所示。
    获取模块 >> 存储模块 <=> 检测模块
                 v
               接口模块

生成模块负责生成新的Cookies。此模块会从存储模块逐个拿取账号的用户名和密码，然后模拟登录目标页面，判断登录成功，就将Cookies返回并交给存储模块存储。

存储模块负责存储每个账号的用户名密码以及每个账号对应的Cookies信息，同时还需要提供一些方法来实现方便的存取操作。

检测模块需要定时检测数据库中的Cookies。在这里我们需要设置一个检测链接，不同的站点检测链接不同，检测模块会逐个拿取账号对应的Cookies去请求链接，如果返回的状态是有效的，那么此Cookies没有失效，否则Cookies失效并移除。接下来等待生成模块重新生成即可。

接口模块需要用API来提供对外服务的接口。由于可用的Cookies可能有多个，我们可以随机返回Cookies的接口，这样保证每个Cookies都有可能被取到。Cookies越多，每个Cookies被取到的概率就会越小，从而减少被封号的风险。


#微博账号购买链接  http://www.onini.cn/gyzp8qar?from=groupmessage&mType=Group




### 对付基于 ip 的反爬
















### 报错
1.
    https://blog.csdn.net/speverriver/article/details/78689722

2.